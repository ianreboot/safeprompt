2:I[9107,[],"ClientPageRoot"]
3:I[9696,["972","static/chunks/972-113806ce51de795a.js","429","static/chunks/429-cc2b3977c0ae8b06.js","931","static/chunks/app/page-771378b3ccc1b861.js"],"default",1]
4:I[8003,["185","static/chunks/app/layout-1efa34e3a0151378.js"],""]
6:I[4707,[],""]
7:I[6423,[],""]
5:T537,{"@context":"https://schema.org","@type":"FAQPage","mainEntity":[{"@type":"Question","name":"What is prompt injection?","acceptedAnswer":{"@type":"Answer","text":"Prompt injection is a security vulnerability where attackers manipulate AI systems by inserting malicious instructions into user inputs, causing the AI to perform unintended actions."}},{"@type":"Question","name":"How fast is SafePrompt?","acceptedAnswer":{"@type":"Answer","text":"SafePrompt processes requests in under 100ms, with regex validation taking only 5ms and AI validation completing in 50-100ms."}},{"@type":"Question","name":"Is there a free tier?","acceptedAnswer":{"@type":"Answer","text":"Yes, SafePrompt offers a free tier with 1,000 API calls per month, perfect for testing and small projects."}},{"@type":"Question","name":"How do I integrate SafePrompt?","acceptedAnswer":{"@type":"Answer","text":"Integration is simple - just make a POST request to our API endpoint with your prompt. We provide SDKs for popular languages and comprehensive documentation."}},{"@type":"Question","name":"What makes SafePrompt different?","acceptedAnswer":{"@type":"Answer","text":"SafePrompt is developer-first with transparent pricing, no sales calls, simple integration, and fast response times. We focus on making security accessible, not enterprise complexity."}}]}0:["R62XgS93V24eSdD0L19E3",[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",{"children":["__PAGE__",{},[["$L1",["$","$L2",null,{"props":{"params":{},"searchParams":{}},"Component":"$3"}],null],null],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/ae3c7a1685d12edb.css","precedence":"next","crossOrigin":"$undefined"}]],["$","html",null,{"lang":"en","className":"dark","children":["$","body",null,{"className":"__className_f367f3 bg-background text-foreground min-h-screen","children":[["$","$L4",null,{"id":"structured-data-organization","type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"Organization\",\"name\":\"SafePrompt\",\"url\":\"https://safeprompt.dev\",\"logo\":\"https://safeprompt.dev/logo.png\",\"description\":\"Developer-first API service that prevents prompt injection attacks in AI applications\",\"contactPoint\":{\"@type\":\"ContactPoint\",\"contactType\":\"customer support\",\"url\":\"https://safeprompt.dev/contact\"},\"sameAs\":[\"https://github.com/ianreboot/safeprompt\"]}"},"strategy":"afterInteractive"}],["$","$L4",null,{"id":"structured-data-product","type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"SoftwareApplication\",\"name\":\"SafePrompt API\",\"applicationCategory\":\"SecurityApplication\",\"operatingSystem\":\"All\",\"description\":\"Stop prompt injection in one line of code. Fast, simple, transparent API for AI security.\",\"url\":\"https://safeprompt.dev\",\"author\":{\"@type\":\"Organization\",\"name\":\"SafePrompt\"},\"offers\":{\"@type\":\"Offer\",\"price\":\"0\",\"priceCurrency\":\"USD\",\"priceValidUntil\":\"2025-12-31\",\"availability\":\"https://schema.org/InStock\",\"description\":\"Free tier: 1,000 API calls/month\"},\"aggregateRating\":{\"@type\":\"AggregateRating\",\"ratingValue\":\"4.8\",\"ratingCount\":\"127\",\"bestRating\":\"5\",\"worstRating\":\"1\"},\"featureList\":[\"Prompt injection detection\",\"Multi-layer validation\",\"Sub-100ms response time\",\"99.9% uptime SLA\",\"RESTful API\",\"Real-time monitoring\"]}"},"strategy":"afterInteractive"}],["$","$L4",null,{"id":"structured-data-faq","type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$5"},"strategy":"afterInteractive"}],["$","div",null,{"className":"grid-background fixed inset-0 z-0"}],["$","div",null,{"className":"relative z-10","children":["$","$L6",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L7",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]}]]}]}]],null],null],["$L8",null]]]]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"SafePrompt - Stop Prompt Injection in One Line of Code"}],["$","meta","3",{"name":"description","content":"Protect your AI applications from prompt injection attacks with simple, transparent, developer-first security."}],["$","meta","4",{"name":"author","content":"SafePrompt"}],["$","meta","5",{"name":"keywords","content":"prompt injection, ai security, chatgpt security, llm security, api security"}],["$","meta","6",{"name":"robots","content":"index, follow"}],["$","meta","7",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","meta","8",{"property":"og:title","content":"SafePrompt - Stop Prompt Injection in One Line of Code"}],["$","meta","9",{"property":"og:description","content":"Protect your AI applications from prompt injection attacks."}],["$","meta","10",{"property":"og:url","content":"https://safeprompt.dev"}],["$","meta","11",{"property":"og:site_name","content":"SafePrompt"}],["$","meta","12",{"property":"og:locale","content":"en_US"}],["$","meta","13",{"property":"og:image","content":"https://safeprompt.dev/og-image.png"}],["$","meta","14",{"property":"og:image:width","content":"1200"}],["$","meta","15",{"property":"og:image:height","content":"630"}],["$","meta","16",{"property":"og:type","content":"website"}],["$","meta","17",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","18",{"name":"twitter:title","content":"SafePrompt - Stop Prompt Injection in One Line of Code"}],["$","meta","19",{"name":"twitter:description","content":"Protect your AI applications from prompt injection attacks."}],["$","meta","20",{"name":"twitter:image","content":"https://safeprompt.dev/og-image.png"}],["$","link","21",{"rel":"shortcut icon","href":"/favicon.webp"}],["$","link","22",{"rel":"icon","href":"/favicon.webp"}],["$","link","23",{"rel":"apple-touch-icon","href":"/favicon.webp"}],["$","meta","24",{"name":"next-size-adjust"}]]
1:null
